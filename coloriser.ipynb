{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DOWNLOADER' already exists and is not an empty directory.\n",
      "A subdirectory or file DATA already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/skaldek/ImageNet-Datasets-Downloader DOWNLOADER\n",
    "!mkdir DATA\n",
    "!mkdir PRECALCULATED\n",
    "!mkdir CHECKPOINTS\n",
    "# vehicle armored car fishing boat airplane bumper car\n",
    "!python DOWNLOADER/downloader.py \\\n",
    "    -data_root DATA \\\n",
    "    -use_class_list True \\\n",
    "    -class_list n06255081 n02739889 n03351262 n02691156 n02918964 \\\n",
    "    -images_per_class 10000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import color\n",
    "\n",
    "import dataset\n",
    "import model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show(images, size=(10, 10), grayscale=False):\n",
    "    plt.figure()\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "\n",
    "    rows = int(np.ceil(len(images) / 3.0))\n",
    "\n",
    "    if grayscale:\n",
    "        m = images\n",
    "    else:\n",
    "        m = model.Model.lab_to_rgb(images)\n",
    "    for i, image in enumerate(m):\n",
    "        plt.subplot(rows, 3, i + 1)\n",
    "\n",
    "        if grayscale:\n",
    "            image = image[0, :, :]\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HPfuPCxgC0Mv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def H_inv(y_batch, q_to_ab, neighbours):\n",
    "    # values between 0 and 100 and -110 to +110\n",
    "    b, c, h, w = y_batch.shape\n",
    "    y_batch_permuted = y_batch.permute(1, 0, 2, 3).reshape(2, -1)\n",
    "    cdist = torch.cdist(q_to_ab, y_batch_permuted.t())\n",
    "    nns = (cdist.sort(dim=0)[1])[:neighbours, :]  # 5, 64*64*8\n",
    "    nn_gauss = y_batch_permuted.new_zeros(neighbours, b * h * w)\n",
    "\n",
    "    sigma = 5\n",
    "    norm = 1 / (2 * np.pi * sigma)\n",
    "    for i in range(neighbours):\n",
    "        nn_gauss[i, :] = norm * torch.exp(\n",
    "            -torch.sum((q_to_ab[nns[i, :], :].t() - y_batch_permuted) ** 2, dim=0) / (2 * sigma ** 2))\n",
    "\n",
    "    # normalize\n",
    "    nn_gauss /= nn_gauss.sum(dim=0, keepdim=True)\n",
    "    bins = 313\n",
    "    q = y_batch.new_zeros(bins, b * h * w)\n",
    "    q[nns, torch.arange(b * h * w).repeat(neighbours, 1)] = nn_gauss\n",
    "    Z = q.reshape(bins, b, h, w).permute(1, 0, 2, 3)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def H(Z_batch, T, q_to_ab):\n",
    "    if T == 0:\n",
    "        mode = Z_batch.max(dim=1, keepdim=True)[1]\n",
    "\n",
    "        _, _, h, w = mode.shape\n",
    "        ab = torch.stack([\n",
    "            q_to_ab.index_select(\n",
    "                0, mode_.flatten()\n",
    "            ).reshape(h, w, 2).permute(2, 0, 1)\n",
    "\n",
    "            for mode_ in mode\n",
    "        ])\n",
    "    else:\n",
    "        Z_batch = torch.exp(Z_batch / T)\n",
    "        Z_batch /= Z_batch.sum(dim=1, keepdim=True)\n",
    "\n",
    "        a = torch.tensordot(Z_batch, q_to_ab[:, 0], dims=((1,), (0,))).unsqueeze(1)\n",
    "        b = torch.tensordot(Z_batch, q_to_ab[:, 1], dims=((1,), (0,))).unsqueeze(1)\n",
    "\n",
    "        ab = torch.cat((a, b), dim=1)\n",
    "    return ab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def compute_p(dataloader, Q_shape):\n",
    "    p = torch.zeros(Q_shape)\n",
    "    for idx, (_, Z_batch) in enumerate(dataloader):\n",
    "        if (idx % 1 == 0):\n",
    "            print(\"idx: \", idx)\n",
    "\n",
    "        if idx > 100:\n",
    "            break\n",
    "\n",
    "        # Z_batch: (8, 313, 64, 64)\n",
    "        b, Q, H, W, = Z_batch.shape\n",
    "        Z_batch = torch.permute(Z_batch, (0, 2, 3, 1))  # b, H, W, Q,\n",
    "\n",
    "        # (b*H*W, Q)\n",
    "        Z_batch_flat = Z_batch.reshape((b * H * W, Q_shape))\n",
    "        p_batch = torch.sum(Z_batch_flat, dim=0)\n",
    "        p += p_batch\n",
    "    return p / torch.sum(p)\n",
    "\n",
    "\n",
    "def compute_w(p, lamb, Q):\n",
    "    w = 1 / (((1 - lamb) * p) + lamb / Q)\n",
    "    return w / sum(p * w)\n",
    "\n",
    "\n",
    "def v(Z_batch, weights_to_rebalance):\n",
    "    w = weights_to_rebalance\n",
    "    b, c, H, W = Z_batch.shape\n",
    "    Z_batch_flattened = torch.reshape(Z_batch, (b, c, H * W))\n",
    "    batch_idxs = torch.arange(b)\n",
    "    # shape: (8, 64*64)\n",
    "    idxs = torch.argmax(Z_batch_flattened[batch_idxs, :, :], dim=1)\n",
    "    return w[idxs].reshape(b, 1, H, W)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oz7E1a0OxFZb",
    "outputId": "45f074a4-436e-4558-bbd3-508d695b2d2a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2186\n",
      "train:  1760\n",
      "test:  224\n",
      "val:  224\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(dataset)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "data = dataset.Dataset(176, True)\n",
    "\n",
    "print(len(data))\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(data, [0.8, 0.1, 0.1], torch.Generator().manual_seed(0))\n",
    "\n",
    "train = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "test = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "val = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "print(\"train: \", len(train) * batch_size)\n",
    "print(\"test: \", len(test) * batch_size)\n",
    "print(\"val: \", len(val) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "visualization_data = dataset.Dataset(256, False)\n",
    "visualization = DataLoader(visualization_data, batch_size=6, shuffle=True, num_workers=num_workers, collate_fn=dataset.collate_fn)\n",
    "images = next(iter(visualization))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "q_to_ab = torch.from_numpy(np.load(\"PRECALCULATED/ab-gamut.npy\")).float().to(device)\n",
    "q_length = q_to_ab.shape[0]\n",
    "\n",
    "must_compute_p = False\n",
    "if must_compute_p:\n",
    "    p = compute_p(train, q_length)\n",
    "    torch.save(p, \"PRECALCULATED/p.pt\")\n",
    "# p = torch.load(\"p.pt\").to(device)\n",
    "p = torch.from_numpy(np.load(\"PRECALCULATED/p-prior.npy\")).to(device)\n",
    "\n",
    "weights_to_rebalance = compute_w(p, lamb=0.5, Q=q_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 4.91241402643485, Validation loss: 4.687921905479719, Time: 0:01:19.673523\n",
      "Epoch: 1, Train loss: 4.426848330679494, Validation loss: 4.273897442553041, Time: 0:01:18.228952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m cross_entropy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mcross_entropy\n\u001B[0;32m     12\u001B[0m m \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mModel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclean\u001B[39m\u001B[38;5;124m\"\u001B[39m, q_length, h, h_inv, cross_entropy_rebalanced)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Users\\wgaud\\Downloads\\ImageColoring\\model.py:157\u001B[0m, in \u001B[0;36mModel.train_model\u001B[1;34m(self, train, val, epochs)\u001B[0m\n\u001B[0;32m    154\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimiser\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m--> 157\u001B[0m epoch_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# print(f\"Batch: {i}, Loss: {loss.item()}\")\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(model)\n",
    "\n",
    "h_inv = lambda ab: H_inv(ab, q_to_ab, 5)\n",
    "h = lambda z: H(z, 0.38, q_to_ab)\n",
    "\n",
    "v_prepared = lambda z: v(z, weights_to_rebalance)\n",
    "cross_entropy_rebalanced = lambda y_pred, y: model.Model.cross_entropy_rebalanced(y_pred, y, v_prepared)\n",
    "cross_entropy = model.Model.cross_entropy\n",
    "\n",
    "m = model.Model(\"clean\", q_length, h, h_inv, cross_entropy_rebalanced).to(device)\n",
    "m.train_model(train, val, 100)\n",
    "\n",
    "m.test(train)\n",
    "\n",
    "m.test(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}