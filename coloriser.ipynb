{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DOWNLOADER' already exists and is not an empty directory.\n",
      "A subdirectory or file DATA already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/skaldek/ImageNet-Datasets-Downloader DOWNLOADER\n",
    "!mkdir DATA\n",
    "!mkdir PRECALCULATED\n",
    "!mkdir CHECKPOINTS\n",
    "# vehicle armored car fishing boat airplane bumper car\n",
    "!python DOWNLOADER/downloader.py \\\n",
    "    -data_root DATA \\\n",
    "    -use_class_list True \\\n",
    "    -class_list n06255081 n02739889 n03351262 n02691156 n02918964 \\\n",
    "    -images_per_class 10000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import color\n",
    "\n",
    "import dataset\n",
    "import model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show(images, size=(10, 10), grayscale=False):\n",
    "    plt.figure()\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "\n",
    "    rows = int(np.ceil(len(images) / 3.0))\n",
    "\n",
    "    if grayscale:\n",
    "        m = images\n",
    "    else:\n",
    "        m = model.Model.lab_to_rgb(images)\n",
    "    for i, image in enumerate(m):\n",
    "        plt.subplot(rows, 3, i + 1)\n",
    "\n",
    "        if grayscale:\n",
    "            image = image[0, :, :]\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HPfuPCxgC0Mv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def H_inv(y_batch, q_to_ab, neighbours):\n",
    "    # values between 0 and 100 and -110 to +110\n",
    "    b, c, h, w = y_batch.shape\n",
    "    y_batch_permuted = y_batch.permute(1, 0, 2, 3).reshape(2, -1)\n",
    "    cdist = torch.cdist(q_to_ab, y_batch_permuted.t())\n",
    "    nns = (cdist.sort(dim=0)[1])[:neighbours, :]  # 5, 64*64*8\n",
    "    nn_gauss = y_batch_permuted.new_zeros(neighbours, b * h * w)\n",
    "\n",
    "    sigma = 5\n",
    "    norm = 1 / (2 * np.pi * sigma)\n",
    "    for i in range(neighbours):\n",
    "        nn_gauss[i, :] = norm * torch.exp(\n",
    "            -torch.sum((q_to_ab[nns[i, :], :].t() - y_batch_permuted) ** 2, dim=0) / (2 * sigma ** 2))\n",
    "\n",
    "    # normalize\n",
    "    nn_gauss /= nn_gauss.sum(dim=0, keepdim=True)\n",
    "    bins = 313\n",
    "    q = y_batch.new_zeros(bins, b * h * w)\n",
    "    q[nns, torch.arange(b * h * w).repeat(neighbours, 1)] = nn_gauss\n",
    "    Z = q.reshape(bins, b, h, w).permute(1, 0, 2, 3)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def H(Z_batch, T, q_to_ab):\n",
    "    if T == 0:\n",
    "        mode = Z_batch.max(dim=1, keepdim=True)[1]\n",
    "\n",
    "        _, _, h, w = mode.shape\n",
    "        ab = torch.stack([\n",
    "            q_to_ab.index_select(\n",
    "                0, mode_.flatten()\n",
    "            ).reshape(h, w, 2).permute(2, 0, 1)\n",
    "\n",
    "            for mode_ in mode\n",
    "        ])\n",
    "    else:\n",
    "        Z_batch = torch.exp(Z_batch / T)\n",
    "        Z_batch /= Z_batch.sum(dim=1, keepdim=True)\n",
    "\n",
    "        a = torch.tensordot(Z_batch, q_to_ab[:, 0], dims=((1,), (0,))).unsqueeze(1)\n",
    "        b = torch.tensordot(Z_batch, q_to_ab[:, 1], dims=((1,), (0,))).unsqueeze(1)\n",
    "\n",
    "        ab = torch.cat((a, b), dim=1)\n",
    "    return ab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def compute_p(dataloader, Q_shape):\n",
    "    p = torch.zeros(Q_shape)\n",
    "    for idx, (_, Z_batch) in enumerate(dataloader):\n",
    "        if (idx % 1 == 0):\n",
    "            print(\"idx: \", idx)\n",
    "\n",
    "        if idx > 100:\n",
    "            break\n",
    "\n",
    "        # Z_batch: (8, 313, 64, 64)\n",
    "        b, Q, H, W, = Z_batch.shape\n",
    "        Z_batch = torch.permute(Z_batch, (0, 2, 3, 1))  # b, H, W, Q,\n",
    "\n",
    "        # (b*H*W, Q)\n",
    "        Z_batch_flat = Z_batch.reshape((b * H * W, Q_shape))\n",
    "        p_batch = torch.sum(Z_batch_flat, dim=0)\n",
    "        p += p_batch\n",
    "        p /= p.sum()\n",
    "\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        p = gaussian_filter(p, sigma=5)\n",
    "        p /= p.sum()\n",
    "    return p / torch.sum(p)\n",
    "\n",
    "\n",
    "def compute_w(p, lamb):\n",
    "    Q = (p > 0).sum()\n",
    "    w = 1 / (((1 - lamb) * p) + lamb / Q)\n",
    "    return w / sum(p * w)\n",
    "\n",
    "\n",
    "def v(Z_batch, weights_to_rebalance):\n",
    "    w = weights_to_rebalance\n",
    "    b, c, H, W = Z_batch.shape\n",
    "    Z_batch_flattened = torch.reshape(Z_batch, (b, c, H * W))\n",
    "    batch_idxs = torch.arange(b)\n",
    "    # shape: (8, 64*64)\n",
    "    idxs = torch.argmax(Z_batch_flattened[batch_idxs, :, :], dim=1)\n",
    "    return w[idxs].reshape(b, 1, H, W)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oz7E1a0OxFZb",
    "outputId": "45f074a4-436e-4558-bbd3-508d695b2d2a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2186\n",
      "train:  1760\n",
      "test:  224\n",
      "val:  224\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(dataset)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "data = dataset.Dataset(176, True)\n",
    "\n",
    "print(len(data))\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(data, [0.8, 0.1, 0.1], torch.Generator().manual_seed(0))\n",
    "\n",
    "train = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "test = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "val = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "print(\"train: \", len(train) * batch_size)\n",
    "print(\"test: \", len(test) * batch_size)\n",
    "print(\"val: \", len(val) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "visualization_data = dataset.Dataset(256, False)\n",
    "visualization = DataLoader(visualization_data, batch_size=6, shuffle=True, num_workers=num_workers, collate_fn=dataset.collate_fn)\n",
    "images = next(iter(visualization))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "q_to_ab = torch.from_numpy(np.load(\"PRECALCULATED/ab-gamut.npy\")).float().to(device)\n",
    "q_length = q_to_ab.shape[0]\n",
    "\n",
    "must_compute_p = False\n",
    "if must_compute_p:\n",
    "    p = compute_p(train, q_length)\n",
    "    torch.save(p, \"PRECALCULATED/p.pt\")\n",
    "# p = torch.load(\"p.pt\").to(device)\n",
    "p = torch.from_numpy(np.load(\"PRECALCULATED/p-prior.npy\")).to(device)\n",
    "\n",
    "weights_to_rebalance = compute_w(p, lamb=0.5, Q=q_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 4.3810412883758545, Validation loss: 3.530084950583322, Time: 0:01:20.909590\n",
      "Epoch: 1, Train loss: 3.2033042821017177, Validation loss: 3.0646839823041643, Time: 0:01:18.710477\n",
      "Epoch: 2, Train loss: 3.056344591487538, Validation loss: 3.018699816295079, Time: 0:01:17.768611\n",
      "Epoch: 3, Train loss: 3.0135816617445514, Validation loss: 2.932027748652867, Time: 0:01:19.826934\n",
      "Epoch: 4, Train loss: 2.9581963018937545, Validation loss: 2.9522554193224226, Time: 0:01:18.995974\n",
      "Epoch: 5, Train loss: 2.943559915369207, Validation loss: 2.93680248941694, Time: 0:01:20.086969\n",
      "Epoch: 6, Train loss: 2.9192058823325415, Validation loss: 2.945199591772897, Time: 0:01:21.802135\n",
      "Epoch: 7, Train loss: 2.9387190081856467, Validation loss: 2.880614689418248, Time: 0:01:21.681511\n",
      "Epoch: 8, Train loss: 2.901062995737249, Validation loss: 2.856006452015468, Time: 0:01:20.769247\n",
      "Epoch: 9, Train loss: 2.900050648775968, Validation loss: 2.813748870577131, Time: 0:01:23.063557\n",
      "Epoch: 10, Train loss: 2.897629633816806, Validation loss: 2.8465585708618164, Time: 0:01:20.950709\n",
      "Epoch: 11, Train loss: 2.8801733927293256, Validation loss: 2.86925322668893, Time: 0:01:20.385838\n",
      "Epoch: 12, Train loss: 2.8613034638491546, Validation loss: 2.8184745992933, Time: 0:01:21.713588\n",
      "Epoch: 13, Train loss: 2.8655888730829413, Validation loss: 2.7835069043295726, Time: 0:01:21.198076\n",
      "Epoch: 14, Train loss: 2.8528895074670966, Validation loss: 2.764972312109811, Time: 0:01:21.766756\n",
      "Epoch: 15, Train loss: 2.8522471644661644, Validation loss: 2.8464502607073103, Time: 0:01:21.562284\n",
      "Epoch: 16, Train loss: 2.841153873096813, Validation loss: 2.805455139705113, Time: 0:01:20.277901\n",
      "Epoch: 17, Train loss: 2.8450894659215753, Validation loss: 2.7831429413386752, Time: 0:01:21.081182\n",
      "Epoch: 18, Train loss: 2.8233478372747247, Validation loss: 2.8324782167162215, Time: 0:01:21.930951\n",
      "Epoch: 19, Train loss: 2.8276927081021395, Validation loss: 2.773043087550572, Time: 0:01:21.472400\n",
      "Epoch: 20, Train loss: 2.818604677373713, Validation loss: 2.8060383456093922, Time: 0:01:19.773001\n",
      "Epoch: 21, Train loss: 2.821649338982322, Validation loss: 2.759494815553938, Time: 0:01:19.787704\n",
      "Epoch: 22, Train loss: 2.7989655928178268, Validation loss: 2.8209078311920166, Time: 0:01:19.866206\n",
      "Epoch: 23, Train loss: 2.807925241643732, Validation loss: 2.793249641145979, Time: 0:01:20.752283\n",
      "Epoch: 24, Train loss: 2.801159221475775, Validation loss: 2.7823374271392822, Time: 0:01:19.878046\n",
      "Epoch: 25, Train loss: 2.823821679028598, Validation loss: 2.785276549203055, Time: 0:01:19.992023\n",
      "Epoch: 26, Train loss: 2.7793122204867275, Validation loss: 2.8282886913844516, Time: 0:01:19.841681\n",
      "Epoch: 27, Train loss: 2.7962396188215775, Validation loss: 2.792510952268328, Time: 0:01:19.859698\n",
      "Epoch: 28, Train loss: 2.798314805464311, Validation loss: 2.757039342607771, Time: 0:01:19.808663\n",
      "Epoch: 29, Train loss: 2.7890302181243896, Validation loss: 2.7788260323660716, Time: 0:01:20.826184\n",
      "Epoch: 30, Train loss: 2.789760433543812, Validation loss: 2.824040481022426, Time: 0:01:19.752024\n",
      "Epoch: 31, Train loss: 2.79167330048301, Validation loss: 2.6887970311301097, Time: 0:01:20.028871\n",
      "Epoch: 32, Train loss: 2.777464892647483, Validation loss: 2.7730134555271695, Time: 0:01:21.936244\n",
      "Epoch: 33, Train loss: 2.75699838291515, Validation loss: 2.766061169760568, Time: 0:01:19.699065\n",
      "Epoch: 34, Train loss: 2.8154144590551202, Validation loss: 2.729231834411621, Time: 0:01:19.970630\n",
      "Epoch: 35, Train loss: 2.760532132062045, Validation loss: 2.7066146646227156, Time: 0:01:20.368256\n",
      "Epoch: 36, Train loss: 2.7574699445204303, Validation loss: 2.753737074988229, Time: 0:01:19.613574\n",
      "Epoch: 37, Train loss: 2.774923732063987, Validation loss: 2.791501726422991, Time: 0:01:19.651291\n",
      "Epoch: 38, Train loss: 2.7595037026838822, Validation loss: 2.793440886906215, Time: 0:01:21.367282\n",
      "Epoch: 39, Train loss: 2.7594661582599986, Validation loss: 2.755071231297084, Time: 0:01:22.198678\n",
      "Epoch: 40, Train loss: 2.7492963097312235, Validation loss: 2.7881672041756764, Time: 0:01:20.187929\n",
      "Epoch: 41, Train loss: 2.767466081272472, Validation loss: 2.7436532293047224, Time: 0:01:19.991001\n",
      "Epoch: 42, Train loss: 2.748779938437722, Validation loss: 2.740024055753435, Time: 0:01:20.522518\n",
      "Epoch: 43, Train loss: 2.738389387997714, Validation loss: 2.709073509488787, Time: 0:01:22.585742\n",
      "Epoch: 44, Train loss: 2.73543759692799, Validation loss: 2.725313561303275, Time: 0:01:25.173577\n",
      "Epoch: 45, Train loss: 2.774029775099321, Validation loss: 2.718883650643485, Time: 0:01:24.958280\n",
      "Epoch: 46, Train loss: 2.7459495891224255, Validation loss: 2.8081842150006975, Time: 0:01:23.098757\n",
      "Epoch: 47, Train loss: 2.763659780675715, Validation loss: 2.7566604614257812, Time: 0:01:24.088352\n",
      "Epoch: 48, Train loss: 2.7433892466805196, Validation loss: 2.7849462032318115, Time: 0:01:26.093157\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(model)\n",
    "\n",
    "h_inv = lambda ab: H_inv(ab, q_to_ab, 1)\n",
    "h = lambda z: H(z, 0.38, q_to_ab)\n",
    "\n",
    "v_prepared = lambda z: v(z, weights_to_rebalance)\n",
    "cross_entropy_rebalanced = lambda y_pred, y: model.Model.cross_entropy_rebalanced(y_pred, y, v_prepared)\n",
    "cross_entropy = model.Model.cross_entropy\n",
    "\n",
    "m = model.Model(\"onehot\", q_length, h, h_inv, cross_entropy).to(device)\n",
    "m.train_model(train, val, 100)\n",
    "\n",
    "m.test(train)\n",
    "\n",
    "m.test(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show(images)\n",
    "show(m.predict(images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}